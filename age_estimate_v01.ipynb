{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from openai import OpenAI #estamos la clase concreta OpenAI del módulo openai\n",
    "from dotenv import load_dotenv #importamos una función concreta del módulo\n",
    "load_dotenv(\"template.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a la clave de API de OpenAI\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Asegurarte de que la clave de API se haya cargado correctamente\n",
    "if api_key is None:\n",
    "    raise ValueError(\"La clave de API no está configurada en el archivo .env\")\n",
    "    \n",
    "client = OpenAI() #creando un objeto de la clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>AoA</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>¡aba!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hinojosa et al. (2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¡abur!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hinojosa et al. (2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>¡achís!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hinojosa et al. (2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>¡adiós!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hinojosa et al. (2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>¡aghgghh!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hinojosa et al. (2021)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  AoA                  Source\n",
       "0      ¡aba!  NaN  Hinojosa et al. (2021)\n",
       "1     ¡abur!  NaN  Hinojosa et al. (2021)\n",
       "2    ¡achís!  NaN  Hinojosa et al. (2021)\n",
       "3    ¡adiós!  NaN  Hinojosa et al. (2021)\n",
       "4  ¡aghgghh!  NaN  Hinojosa et al. (2021)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_folder = os.getenv(\"DATASET_FOLDER\")\n",
    "dataset_path = str(dataset_folder) + \"GPT_estimates_AoA_v1.xlsx\"\n",
    "\n",
    "df = pd.read_excel(dataset_path)\n",
    "#df = df.sample(30)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION DECLARATION\n",
    "\n",
    "def extract_data(new_line):\n",
    "\tres = new_line[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "\tres = json.loads(res)\n",
    "\treturn res\n",
    "\n",
    "def create_file_from_tasks(tasks,file_name):\n",
    "\twith open(file_name, 'w') as file:\n",
    "\t\tfor obj in tasks:\n",
    "\t\t\tfile.write(json.dumps(obj) + '\\n')\n",
    "\n",
    "\n",
    "def create_batch(file_name):\n",
    "\tbatch_file = client.files.create(\n",
    "\t\tfile = open(file_name, \"rb\"),\n",
    "\t\tpurpose = \"batch\"\n",
    "\t)\n",
    "\tbatch_job = client.batches.create(\n",
    "\t\tinput_file_id = batch_file.id,\n",
    "\t\tendpoint = \"/v1/chat/completions\",\n",
    "\t\tcompletion_window = \"24h\"\n",
    "\t)\n",
    "\treturn batch_job\n",
    "\n",
    "def get_line_file(file_name,line,extract_func):\n",
    "\twith open(file_name, 'r') as f:\n",
    "\t\tfor line_number, theline in enumerate(f):\n",
    "\t\t\tif line_number == line:\n",
    "\t\t\t\tres = theline\n",
    "\t\t\t\tbreak\n",
    "\tres = json.loads(res)\n",
    "\treturn extract_func(res)\n",
    "\n",
    "def generate_task(index,prompt,desc):\n",
    "\ttask = {\n",
    "        \"custom_id\": f\"task-{index}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            # Esto es lo que tendrías en tu llamada a la API de Chat Completions\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"temperature\": 0,\n",
    "            \"response_format\": { \n",
    "                \"type\": \"json_object\"\n",
    "            },\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": desc\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    }\n",
    "\treturn task\n",
    "\n",
    "def create_task_from_json(json_object,index,prompt):\n",
    "\tdesc = json.dumps({\"palabra\":json_object[\"Word\"]})\n",
    "\ttask = generate_task(\n",
    "\t\tindex, prompt,desc,\n",
    "\t)\n",
    "\treturn task\n",
    "\n",
    "def create_task_array_from_dataframe(df,prompt):\n",
    "\ttasks = []\n",
    "\tfor index, row in df.iterrows():\n",
    "\t\ttask = create_task_from_json(row,index,prompt)\n",
    "\t\ttasks.append(task)\n",
    "\treturn tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROMPTS\n",
    "\n",
    "#AGE PROMPT\n",
    "categorize_system_prompt_paraphrase ='''\n",
    "La edad de adquisición (AoA) de una palabra se refiere a la edad en la que se aprendió una palabra por primera vez. \n",
    "En concreto, cuándo una persona habría entendido por primera vez esa palabra si alguien la hubiera utilizado delante de ella, incluso cuando aún no la hubiera dicho, leído o escrito. \n",
    "Calcule la edad media de adquisición (AoA) de la palabra {palabra} para un hablante nativo de español.\n",
    "\n",
    "El formato de salida debe ser un objeto JSON: {AoA: número //AoA de la palabra expresado en años, puede incluir decimales, Word: palabra //string}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set output folder\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "def out_file(file_name): return (str(output_folder) + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AGE TASK\n",
    "tasks_array = [create_task_array_from_dataframe(df,categorize_system_prompt_paraphrase)]\n",
    "file_array = [out_file(\"batch_job_mmlu_age.jsonl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_files/batch_job_mmlu_age_00.jsonl\n",
      "output_files/batch_job_mmlu_age_01.jsonl\n",
      "output_files/batch_job_mmlu_age_02.jsonl\n",
      "output_files/batch_job_mmlu_age_03.jsonl\n",
      "output_files/batch_job_mmlu_age_04.jsonl\n",
      "output_files/batch_job_mmlu_age_05.jsonl\n",
      "output_files/batch_job_mmlu_age_06.jsonl\n",
      "output_files/batch_job_mmlu_age_07.jsonl\n",
      "output_files/batch_job_mmlu_age_08.jsonl\n",
      "output_files/batch_job_mmlu_age_09.jsonl\n",
      "output_files/batch_job_mmlu_age_10.jsonl\n",
      "output_files/batch_job_mmlu_age_11.jsonl\n",
      "output_files/batch_job_mmlu_age_12.jsonl\n"
     ]
    }
   ],
   "source": [
    "#DIVIDE TASK\n",
    "def divide_task(tasks_array,file_array,task_index,num_tasks):\n",
    "\tres_task_array = []\n",
    "\tres_file_array = []\n",
    "\ttask_array_to_div = []\n",
    "\tprov_file_name = \"\"\n",
    "\tfor i in range(0,len(tasks_array)):\n",
    "\t\tif(i == task_index):\n",
    "\t\t\ttask_array_to_div = tasks_array[i]\n",
    "\t\t\tprov_file_name = file_array[i]\n",
    "\t\telse:\n",
    "\t\t\tres_task_array.append(tasks_array[i])\n",
    "\t\t\tres_file_array.append(file_array[i])\n",
    "\tindex = 1+int(len(task_array_to_div)/num_tasks)\n",
    "\tfor i in range(0,index):\n",
    "\t\ttasks = []\n",
    "\t\tfor j in range(0,num_tasks):\n",
    "\t\t\tif(i*num_tasks+j < len(task_array_to_div)):\n",
    "\t\t\t\ttasks.append(task_array_to_div[i*num_tasks+j])\n",
    "\t\tres_task_array.append(tasks)\n",
    "\t\tres_file_array.append(prov_file_name.replace(\".json\",\"_\"+\"0\"*(1+int(index/10)-len(str(i)))+str(i)+\".json\"))\n",
    "\treturn res_task_array,res_file_array\n",
    "\n",
    "tasks_array,file_array = divide_task(tasks_array,file_array,0,10000)\n",
    "\n",
    "for i in range(0,len(file_array)):\n",
    "\tprint(file_array[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATE TASK FILES\n",
    "for i in range(0,len(tasks_array)):\n",
    "\tcreate_file_from_tasks(tasks_array[i],file_array[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATE BATCH\n",
    "batch_jobs = []\n",
    "for i in range(0,len(tasks_array)):\n",
    "\tba_jo= create_batch(file_array[i])\n",
    "\tbatch_jobs.append(ba_jo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_67c47e3323808190ab137056e6d590f4', completion_window='24h', created_at=1740930611, endpoint='/v1/chat/completions', input_file_id='file-GJE3g9qXCw3wABCdoECuN8', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1740933863, error_file_id=None, errors=None, expired_at=None, expires_at=1741017011, failed_at=None, finalizing_at=1740933160, in_progress_at=1740930613, metadata=None, output_file_id='file-UTe479b4mThcmedgcjiHga', request_counts=BatchRequestCounts(completed=10000, failed=0, total=10000))\n",
      "completed\n",
      "Batch(id='batch_67c47e3e65d88190ba782c4149adc15e', completion_window='24h', created_at=1740930622, endpoint='/v1/chat/completions', input_file_id='file-AGcyCJqg4tWR8pBhsMUvrX', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1740939232, error_file_id=None, errors=None, expired_at=None, expires_at=1741017022, failed_at=None, finalizing_at=1740938100, in_progress_at=1740930625, metadata=None, output_file_id='file-YDVrgoNSi3DJgZVWtYHzVr', request_counts=BatchRequestCounts(completed=10000, failed=0, total=10000))\n",
      "completed\n",
      "Batch(id='batch_67c47e479f6c8190a3d209176dee48ef', completion_window='24h', created_at=1740930631, endpoint='/v1/chat/completions', input_file_id='file-6Nc3j5v165hBLTRtrTy6r8', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1740936612, error_file_id=None, errors=None, expired_at=None, expires_at=1741017031, failed_at=None, finalizing_at=1740935036, in_progress_at=1740930636, metadata=None, output_file_id='file-Mc5qK7uJf73NNCQWhPdUEV', request_counts=BatchRequestCounts(completed=10000, failed=0, total=10000))\n",
      "completed\n",
      "Batch(id='batch_67c47e5032348190ad7bf4aad953b72b', completion_window='24h', created_at=1740930640, endpoint='/v1/chat/completions', input_file_id='file-TWuGJoYFozxrvUJvNemRiH', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1740939057, error_file_id=None, errors=None, expired_at=None, expires_at=1741017040, failed_at=None, finalizing_at=1740937543, in_progress_at=1740930644, metadata=None, output_file_id='file-4HcCWJjz8ANunXae2FAGM3', request_counts=BatchRequestCounts(completed=10000, failed=0, total=10000))\n",
      "completed\n",
      "Batch(id='batch_67c47e599a508190a376c3c6d6034caf', completion_window='24h', created_at=1740930649, endpoint='/v1/chat/completions', input_file_id='file-Nqjok6qNSeH2raPMzaxRyN', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1740939071, error_file_id=None, errors=None, expired_at=None, expires_at=1741017049, failed_at=None, finalizing_at=1740937544, in_progress_at=1740930653, metadata=None, output_file_id='file-Mf1Xqf4gup8qNK7gHXdr5j', request_counts=BatchRequestCounts(completed=10000, failed=0, total=10000))\n",
      "completed\n",
      "Batch(id='batch_67c47e6218308190b131dd984ad41e12', completion_window='24h', created_at=1740930658, endpoint='/v1/chat/completions', input_file_id='file-Wz4gNKuYNxH86M8YJzaYg2', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1740939271, error_file_id=None, errors=None, expired_at=None, expires_at=1741017058, failed_at=None, finalizing_at=1740938100, in_progress_at=1740930661, metadata=None, output_file_id='file-N9r9ssjDJJ1yS2qyfVnvDe', request_counts=BatchRequestCounts(completed=10000, failed=0, total=10000))\n",
      "completed\n",
      "Batch(id='batch_67c47e6bec288190842712e15fa42aaa', completion_window='24h', created_at=1740930668, endpoint='/v1/chat/completions', input_file_id='file-TY6YYihywSondUUupBvcq4', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1740935927, error_file_id=None, errors=None, expired_at=None, expires_at=1741017068, failed_at=None, finalizing_at=1740934919, in_progress_at=1740930672, metadata=None, output_file_id='file-6Pr6WjAzcLpH7ECtC6JppF', request_counts=BatchRequestCounts(completed=10000, failed=0, total=10000))\n",
      "completed\n",
      "Batch(id='batch_67c47e7625748190b436f7b774b7f8a3', completion_window='24h', created_at=1740930678, endpoint='/v1/chat/completions', input_file_id='file-5J77E6VUBGZ44swMZjK3Gi', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1740935863, error_file_id=None, errors=None, expired_at=None, expires_at=1741017078, failed_at=None, finalizing_at=1740934771, in_progress_at=1740930681, metadata=None, output_file_id='file-5WwBd1KZ9ZAUjYsdutY81j', request_counts=BatchRequestCounts(completed=10000, failed=0, total=10000))\n",
      "completed\n",
      "Batch(id='batch_67c47e8035e8819094cee1c88661743f', completion_window='24h', created_at=1740930688, endpoint='/v1/chat/completions', input_file_id='file-3jxXAAmrz8PhAzy96NxXZd', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1740933536, error_file_id=None, errors=None, expired_at=None, expires_at=1741017088, failed_at=None, finalizing_at=1740932684, in_progress_at=1740930690, metadata=None, output_file_id='file-BWz3MReFoVtzwHS8ogS9Gp', request_counts=BatchRequestCounts(completed=10000, failed=0, total=10000))\n",
      "completed\n",
      "Batch(id='batch_67c47e8a95c88190b3961de5d3979519', completion_window='24h', created_at=1740930698, endpoint='/v1/chat/completions', input_file_id='file-PoxojrwfAtfjbuNvjPJcvg', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1740936364, error_file_id=None, errors=None, expired_at=None, expires_at=1741017098, failed_at=None, finalizing_at=1740935222, in_progress_at=1740930701, metadata=None, output_file_id='file-H3VyFYNa2Jo68sqMTpmKZE', request_counts=BatchRequestCounts(completed=10000, failed=0, total=10000))\n",
      "completed\n",
      "Batch(id='batch_67c47e954f088190beaeb67a3f268392', completion_window='24h', created_at=1740930709, endpoint='/v1/chat/completions', input_file_id='file-X5sGHJSBJCgCTsPUxvs5Pt', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1740938349, error_file_id=None, errors=None, expired_at=None, expires_at=1741017109, failed_at=None, finalizing_at=1740937153, in_progress_at=1740930712, metadata=None, output_file_id='file-Cqhku8XTCpoihMUhzUpct1', request_counts=BatchRequestCounts(completed=10000, failed=0, total=10000))\n",
      "completed\n",
      "Batch(id='batch_67c47e9fab088190b69f61305c00f228', completion_window='24h', created_at=1740930719, endpoint='/v1/chat/completions', input_file_id='file-HVsP5fqmiw8fQvKUUzYXXt', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1740939209, error_file_id=None, errors=None, expired_at=None, expires_at=1741017119, failed_at=None, finalizing_at=1740938100, in_progress_at=1740930723, metadata=None, output_file_id='file-UpHNMTRfpgP1PRg48GFyup', request_counts=BatchRequestCounts(completed=10000, failed=0, total=10000))\n",
      "completed\n",
      "Batch(id='batch_67c47ea83f888190bb5cf055d204e718', completion_window='24h', created_at=1740930728, endpoint='/v1/chat/completions', input_file_id='file-GJooxc4MeH9fmy66Q8AeER', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1740934836, error_file_id=None, errors=None, expired_at=None, expires_at=1741017128, failed_at=None, finalizing_at=1740934083, in_progress_at=1740930731, metadata=None, output_file_id='file-BN8KQWHmwjyHEvvp5RWWv9', request_counts=BatchRequestCounts(completed=7728, failed=0, total=7728))\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "#COMPLETION_CHECK\n",
    "for i in range(0,len(batch_jobs)):\n",
    "\tbatch = batch_jobs[i]\n",
    "\tbatch = client.batches.retrieve(batch.id)\n",
    "\tprint(batch)\n",
    "\tresult_file_id = batch.output_file_id\n",
    "\tprint(batch.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTPUT FILES GENERATOR\n",
    "for i in range(0,len(batch_jobs)):\n",
    "\tbatch = batch_jobs[i]\n",
    "\tbatch = client.batches.retrieve(batch.id)\n",
    "\tresult_file_id = batch.output_file_id\n",
    "\n",
    "\tresult = client.files.content(result_file_id).content\n",
    "\n",
    "\tresult_file_name = file_array[i].replace(\".json\",\"_result.json\")\n",
    "\n",
    "\twith open(result_file_name, 'wb') as file:\n",
    "\t\tfile.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_num 7\n",
      "line_num 75848\n",
      "line {\"id\": \"batch_req_67c490ec34ec81909107fea37f2c588f\", \"custom_id\": \"task-75848\", \"response\": {\"status_code\": 200, \"request_id\": \"72a59adcce863ce1a9b14fb96c92b9e5\", \"body\": {\"id\": \"chatcmpl-B6g408ngFUjZD87HYIBb1yG0vRllW\", \"object\": \"chat.completion\", \"created\": 1740931360, \"model\": \"gpt-4o-mini-2024-07-18\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"{\\\"AoA\\\": 10.5, \\\"Word\\\": \\\"licitamente\", \"refusal\": null}, \"logprobs\": null, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 153, \"completion_tokens\": 15, \"total_tokens\": 168, \"prompt_tokens_details\": {\"cached_tokens\": 0, \"audio_tokens\": 0}, \"completion_tokens_details\": {\"reasoning_tokens\": 0, \"audio_tokens\": 0, \"accepted_prediction_tokens\": 0, \"rejected_prediction_tokens\": 0}}, \"service_tier\": \"default\", \"system_fingerprint\": \"fp_06737a9306\"}}, \"error\": null}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Cleaning function\n",
    "def clean(file_array):\n",
    "\trows = []\n",
    "\terrors = []\n",
    "\tacum = 0\n",
    "\n",
    "\tfor i in range(0,len(file_array)):\n",
    "\t\tf_a = file_array[i].replace(\".json\",\"_result.json\")\n",
    "\t\twith open(f_a, 'r') as f:\n",
    "\t\t\tfor line in f:\n",
    "\t\t\t\trow = df.iloc[acum]\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tdt_a = extract_data(json.loads(line.strip()))\n",
    "\t\t\t\t\trows.append({\n",
    "     \t    \t\t\t\"Word\":row['Word'],\n",
    "\t\t\t\t\t\t \"AoA\":dt_a[\"AoA\"],\n",
    "\t\t\t\t\t\t\"Source\":row['Source']\n",
    "\t\t\t\t\t})\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\trows.append({\n",
    "\t\t\t\t\t\t\"Word\":row['Word'],\n",
    "     \t    \t\t\t\"AoA\":\"NaN\",\n",
    "\t\t\t\t\t\t\"Source\":row['Source']\n",
    "\t\t\t\t\t})\n",
    "\t\t\t\t\tprint(f\"file_num {i}\\nline_num {acum}\\nline {line}\")\n",
    "\t\t\t\t\terrors.append({\n",
    "\t\t\t\t\t\t#\"File_Num\":i,\n",
    "     \t    \t\t\t\"Line_Num\":acum,\n",
    "\t\t\t\t\t\t#\"Line\":line\n",
    "\t\t\t\t\t})\n",
    "\t\t\t\tacum += 1\n",
    "       \t    \n",
    "\treturn pd.DataFrame(rows), pd.DataFrame(errors)\n",
    "\n",
    "file_name = out_file(\"FinalResults.xlsx\")\n",
    "clean_dtset,errors_dtset = clean(file_array)\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(file_name) as writer:\n",
    "\tclean_dtset.to_excel(writer, sheet_name='Results',index=False)\n",
    "\terrors_dtset.to_excel(writer, sheet_name='Errors',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from openai import OpenAI #estamos la clase concreta OpenAI del módulo openai\n",
    "from dotenv import load_dotenv #importamos una función concreta del módulo\n",
    "load_dotenv(\"template.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a la clave de API de OpenAI\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Asegurarte de que la clave de API se haya cargado correctamente\n",
    "if api_key is None:\n",
    "    raise ValueError(\"La clave de API no está configurada en el archivo .env\")\n",
    "    \n",
    "client = OpenAI() #creando un objeto de la clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dataset_folder = \u001b[43mos\u001b[49m.getenv(\u001b[33m\"\u001b[39m\u001b[33mDATASET_FOLDER\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m dataset_path = \u001b[38;5;28mstr\u001b[39m(dataset_folder) + \u001b[33m\"\u001b[39m\u001b[33mAlonso_2014_SpanishAoA.xlsx\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m df = pd.read_excel(dataset_path)\n",
      "\u001b[31mNameError\u001b[39m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_folder = os.getenv(\"DATASET_FOLDER\")\n",
    "dataset_path = str(dataset_folder) + \"Alonso_2014_SpanishAoA.xlsx\"\n",
    "\n",
    "df = pd.read_excel(dataset_path)\n",
    "#df = df.sample(5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION DECLARATION\n",
    "\n",
    "def extract_data(new_line):\n",
    "\tres = new_line[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "\tres = json.loads(res)\n",
    "\treturn res\n",
    "\n",
    "def create_file_from_tasks(tasks,file_name):\n",
    "\twith open(file_name, 'w') as file:\n",
    "\t\tfor obj in tasks:\n",
    "\t\t\tfile.write(json.dumps(obj) + '\\n')\n",
    "\n",
    "\n",
    "def create_batch(file_name):\n",
    "\tbatch_file = client.files.create(\n",
    "\t\tfile = open(file_name, \"rb\"),\n",
    "\t\tpurpose = \"batch\"\n",
    "\t)\n",
    "\tbatch_job = client.batches.create(\n",
    "\t\tinput_file_id = batch_file.id,\n",
    "\t\tendpoint = \"/v1/chat/completions\",\n",
    "\t\tcompletion_window = \"24h\"\n",
    "\t)\n",
    "\treturn batch_job\n",
    "\n",
    "def get_line_file(file_name,line,extract_func):\n",
    "\twith open(file_name, 'r') as f:\n",
    "\t\tfor line_number, theline in enumerate(f):\n",
    "\t\t\tif line_number == line:\n",
    "\t\t\t\tres = theline\n",
    "\t\t\t\tbreak\n",
    "\tres = json.loads(res)\n",
    "\treturn extract_func(res)\n",
    "\n",
    "def generate_task(index,prompt,desc):\n",
    "\ttask = {\n",
    "        \"custom_id\": f\"task-{index}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            # Esto es lo que tendrías en tu llamada a la API de Chat Completions\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"temperature\": 0,\n",
    "            \"response_format\": { \n",
    "                \"type\": \"json_object\"\n",
    "            },\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": desc\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    }\n",
    "\treturn task\n",
    "\n",
    "def create_task_from_json(json_object,index,prompt):\n",
    "\tdesc = json.dumps({\"palabra\":json_object[\"word\"]})\n",
    "\ttask = generate_task(\n",
    "\t\tindex, prompt,desc,\n",
    "\t)\n",
    "\treturn task\n",
    "\n",
    "def create_task_array_from_dataframe(df,prompt):\n",
    "\ttasks = []\n",
    "\tfor index, row in df.iterrows():\n",
    "\t\ttask = create_task_from_json(row,index,prompt)\n",
    "\t\ttasks.append(task)\n",
    "\treturn tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROMPTS\n",
    "\n",
    "#AGE PROMPT\n",
    "categorize_system_prompt_paraphrase ='''\n",
    "La edad de adquisición (AoA) de una palabra se refiere a la edad en la que se aprendió una palabra por primera vez. \n",
    "En concreto, cuándo una persona habría entendido por primera vez esa palabra si alguien la hubiera utilizado delante de ella, incluso cuando aún no la hubiera dicho, leído o escrito. \n",
    "Calcule la edad media de adquisición (AoA) de la palabra {palabra} para un hablante nativo de español.\n",
    "\n",
    "El formato de salida debe ser un objeto JSON: {AoA: número //AoA de la palabra expresado en años, puede incluir decimales, Word: palabra //string}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set output folder\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "def out_file(file_name): return (str(output_folder) + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AGE TASK\n",
    "tasks_array = [create_task_array_from_dataframe(df,categorize_system_prompt_paraphrase)]\n",
    "file_array = [out_file(\"batch_job_mmlu_aoa_alonso.jsonl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATE TASK FILES\n",
    "for i in range(0,len(tasks_array)):\n",
    "\tcreate_file_from_tasks(tasks_array[i],file_array[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATE BATCH\n",
    "batch_jobs = []\n",
    "for i in range(0,len(tasks_array)):\n",
    "\tba_jo= create_batch(file_array[i])\n",
    "\tbatch_jobs.append(ba_jo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_67c61111cc0881909b420a931a884255', completion_window='24h', created_at=1741033745, endpoint='/v1/chat/completions', input_file_id='file-82KjZr2t4jwG55nfei7qxT', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1741052458, error_file_id=None, errors=None, expired_at=None, expires_at=1741120145, failed_at=None, finalizing_at=1741051672, in_progress_at=1741033747, metadata=None, output_file_id='file-BKGHS5UtgLCfL7MZhFpfSc', request_counts=BatchRequestCounts(completed=7039, failed=0, total=7039))\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "#COMPLETION_CHECK\n",
    "for i in range(0,len(batch_jobs)):\n",
    "\tbatch = batch_jobs[i]\n",
    "\tbatch = client.batches.retrieve(batch.id)\n",
    "\tprint(batch)\n",
    "\tresult_file_id = batch.output_file_id\n",
    "\tprint(batch.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTPUT FILES GENERATOR\n",
    "for i in range(0,len(batch_jobs)):\n",
    "\tbatch = batch_jobs[i]\n",
    "\tbatch = client.batches.retrieve(batch.id)\n",
    "\tresult_file_id = batch.output_file_id\n",
    "\n",
    "\tresult = client.files.content(result_file_id).content\n",
    "\n",
    "\tresult_file_name = file_array[i].replace(\".json\",\"_result.json\")\n",
    "\n",
    "\twith open(result_file_name, 'wb') as file:\n",
    "\t\tfile.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson_Corr: 0.7276691992436427\n",
      "Spearman_Corr: 0.787075570973569\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Eliminar caracteres de control ASCII (excepto saltos de línea/tabulación)\n",
    "        text = re.sub(r\"[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]\", \"\", text)\n",
    "        return text.strip()\n",
    "    return text\n",
    "\n",
    "#Cleaning function\n",
    "def clean(file_array):\n",
    "\trows = []\n",
    "\terrors = []\n",
    "\tacum = 0\n",
    "\n",
    "\tf_a = file_array[i].replace(\".json\",\"_result.json\")\n",
    "\twith open(f_a, 'r') as f:\n",
    "\t\tfor line in f:\n",
    "\t\t\trow = df.iloc[acum]\n",
    "\t\t\ttry:\n",
    "\t\t\t\tdt_a = extract_data(json.loads(line.strip()))\n",
    "\t\t\t\trows.append({\n",
    "        \t\t\t\"Word_DB\":row['word'],\n",
    "\t\t\t\t\t\"AoA_DB\":row[\"averageAoA\"],\n",
    "\t\t\t\t\t\"Word\":clean_text(dt_a['Word']),\n",
    "\t\t\t\t\t\"AoA\":clean_text(dt_a[\"AoA\"]),\n",
    "\t\t\t\t})\n",
    "\t\t\texcept:\n",
    "\t\t\t\trows.append({\n",
    "\t\t\t\t\t\"Word_DB\":row['word'],\n",
    "\t\t\t\t\t\"AoA_DB\":row[\"averageAoA\"],\n",
    "\t\t\t\t})\n",
    "\t\t\t\tprint(f\"file_num {i}\\nline_num {acum}\\nline {line}\")\t\t\t\t\t\n",
    "\t\t\t\terrors.append({\n",
    "\t\t\t\t\t\t#\"File_Num\":i,\n",
    "     \t    \t\t\t\"Line_Num\":acum,\n",
    "\t\t\t\t\t\t#\"Line\":line\n",
    "\t\t\t\t\t})\n",
    "\t\t\tacum += 1\n",
    "\n",
    "\tdt_rows = pd.DataFrame(rows)\n",
    "\n",
    "\tpearson_corr = dt_rows[['AoA_DB', 'AoA']].corr('pearson')\n",
    "\tprint(f\"Pearson_Corr: {pearson_corr[\"AoA_DB\"][\"AoA\"]}\")\n",
    "\t\n",
    "\tspearman_corr = dt_rows[['AoA_DB', 'AoA']].corr('spearman')\n",
    "\tprint(f\"Spearman_Corr: {spearman_corr[\"AoA_DB\"][\"AoA\"]}\")\n",
    "\t\t    \n",
    "\treturn dt_rows, pd.DataFrame(errors)\n",
    "\n",
    "file_name = out_file(\"FinalResults.xlsx\")\n",
    "clean_dtset,errors_dtset = clean(file_array)\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(file_name) as writer:\n",
    "\tclean_dtset.to_excel(writer, sheet_name='Results',index=False)\n",
    "\terrors_dtset.to_excel(writer, sheet_name='Errors',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

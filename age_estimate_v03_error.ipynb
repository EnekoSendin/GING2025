{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": null,
>>>>>>> d3ffed53bd2a6d389f460ba596891158a6ada8da
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
<<<<<<< HEAD
     "execution_count": 18,
=======
     "execution_count": 1,
>>>>>>> d3ffed53bd2a6d389f460ba596891158a6ada8da
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from openai import OpenAI #estamos la clase concreta OpenAI del módulo openai\n",
    "from dotenv import load_dotenv #importamos una función concreta del módulo\n",
    "load_dotenv(\"template.env\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": null,
>>>>>>> d3ffed53bd2a6d389f460ba596891158a6ada8da
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a la clave de API de OpenAI\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Asegurarte de que la clave de API se haya cargado correctamente\n",
    "if api_key is None:\n",
    "    raise ValueError(\"La clave de API no está configurada en el archivo .env\")\n",
    "    \n",
    "client = OpenAI() #creando un objeto de la clase"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 3,
>>>>>>> d3ffed53bd2a6d389f460ba596891158a6ada8da
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eneko\\Documents\\UniUPM\\BECA\\Lenguaje_interpret\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>averageAoA</th>\n",
       "      <th>SD</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>ItemZScore</th>\n",
       "      <th>OralFreq_Log</th>\n",
       "      <th>WrittenFreq_Subtlex-ESP_Log</th>\n",
       "      <th>WrittenFreq_LEXESP_Log</th>\n",
       "      <th>WrittenFreq_espal_Log</th>\n",
       "      <th>espal_max_lem_cat</th>\n",
       "      <th>max_lem_code</th>\n",
       "      <th>espal_es_num_syll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.443352</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.650147</td>\n",
       "      <td>4.851582</td>\n",
       "      <td>5.984858</td>\n",
       "      <td>4.960556</td>\n",
       "      <td>4.358684</td>\n",
       "      <td>ADPOSITION</td>\n",
       "      <td>SPS00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abajo</td>\n",
       "      <td>2.96</td>\n",
       "      <td>1.369642</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.356683</td>\n",
       "      <td>2.615950</td>\n",
       "      <td>3.940915</td>\n",
       "      <td>2.750508</td>\n",
       "      <td>1.811229</td>\n",
       "      <td>ADVERB</td>\n",
       "      <td>RG</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandonado</td>\n",
       "      <td>6.06</td>\n",
       "      <td>1.658743</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.584383</td>\n",
       "      <td>1.623249</td>\n",
       "      <td>2.872156</td>\n",
       "      <td>2.195900</td>\n",
       "      <td>1.374186</td>\n",
       "      <td>ADJECTIVE</td>\n",
       "      <td>AQ0MSP</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandonar</td>\n",
       "      <td>7.58</td>\n",
       "      <td>1.654801</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.019940</td>\n",
       "      <td>1.806180</td>\n",
       "      <td>2.987666</td>\n",
       "      <td>2.434569</td>\n",
       "      <td>1.653307</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VMN0000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandono</td>\n",
       "      <td>7.22</td>\n",
       "      <td>1.940860</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0.040498</td>\n",
       "      <td>1.602060</td>\n",
       "      <td>2.336460</td>\n",
       "      <td>2.167317</td>\n",
       "      <td>1.328129</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NCMS000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  averageAoA        SD  Min  Max  ItemZScore  OralFreq_Log  \\\n",
       "0           a        2.28  1.443352    1    6   -1.650147      4.851582   \n",
       "1       abajo        2.96  1.369642    1    6   -1.356683      2.615950   \n",
       "2  abandonado        6.06  1.658743    2   10   -0.584383      1.623249   \n",
       "3   abandonar        7.58  1.654801    4   11   -0.019940      1.806180   \n",
       "4    abandono        7.22  1.940860    3   11    0.040498      1.602060   \n",
       "\n",
       "    WrittenFreq_Subtlex-ESP_Log   WrittenFreq_LEXESP_Log  \\\n",
       "0                      5.984858                 4.960556   \n",
       "1                      3.940915                 2.750508   \n",
       "2                      2.872156                 2.195900   \n",
       "3                      2.987666                 2.434569   \n",
       "4                      2.336460                 2.167317   \n",
       "\n",
       "   WrittenFreq_espal_Log espal_max_lem_cat max_lem_code  espal_es_num_syll  \n",
       "0               4.358684        ADPOSITION        SPS00                1.0  \n",
       "1               1.811229            ADVERB           RG                3.0  \n",
       "2               1.374186         ADJECTIVE       AQ0MSP                5.0  \n",
       "3               1.653307              VERB      VMN0000                4.0  \n",
       "4               1.328129              NOUN      NCMS000                4.0  "
      ]
     },
<<<<<<< HEAD
     "execution_count": 20,
=======
     "execution_count": 3,
>>>>>>> d3ffed53bd2a6d389f460ba596891158a6ada8da
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_folder = os.getenv(\"DATASET_FOLDER\")\n",
    "dataset_path = str(dataset_folder) + \"Alonso_2014_SpanishAoA.xlsx\"\n",
    "\n",
    "df = pd.read_excel(dataset_path)\n",
    "#df = df.sample(5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": null,
>>>>>>> d3ffed53bd2a6d389f460ba596891158a6ada8da
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION DECLARATION\n",
    "\n",
    "def generate_task(index,prompt,desc):\n",
    "\ttask = {\n",
    "        \"custom_id\": f\"task-{index}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            # Esto es lo que tendrías en tu llamada a la API de Chat Completions\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"temperature\": 0,\n",
    "            \"response_format\": { \n",
    "                \"type\": \"json_object\"\n",
    "            },\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": desc\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    }\n",
    "\treturn task\n",
    "\n",
    "def generate_fine_tuning(prompt,word,aoa):\n",
    "\tf_t_line = {\n",
    "\t\t\"messages\": [\n",
    "\t\t\t{ \"role\": \"system\", \"content\": str(prompt) },\n",
    "\t\t\t{ \"role\": \"user\", \"content\": str(word) },\n",
    "\t\t\t{ \"role\": \"assistant\", \"content\": str(aoa) }\n",
    "\t\t]}\n",
    "\treturn f_t_line\n",
    "\n",
    "def create_file_from_tasks(tasks,file_name):\n",
    "\twith open(file_name, 'w') as file:\n",
    "\t\tfor obj in tasks:\n",
    "\t\t\tfile.write(json.dumps(obj) + '\\n')\n",
    "\n",
    "def create_fine_tunning_from_json(json_object,prompt):\n",
    "\tword = json_object[\"word\"]\n",
    "\taoa = json_object[\"averageAoA\"]\n",
    "\tf_t_line = generate_fine_tuning(\n",
    "\t\tprompt,word,aoa\n",
    "\t)\n",
    "\treturn f_t_line\n",
    "\n",
    "def create_f_t_array_from_dataframe(df,prompt):\n",
    "\ttasks = []\n",
    "\tfor index, row in df.iterrows():\n",
    "\t\ttask = create_fine_tunning_from_json(row,prompt)\n",
    "\t\ttasks.append(task)\n",
    "\treturn tasks\n",
    "\n",
    "def get_line_file(file_name,line,extract_func):\n",
    "\twith open(file_name, 'r') as f:\n",
    "\t\tfor line_number, theline in enumerate(f):\n",
    "\t\t\tif line_number == line:\n",
    "\t\t\t\tres = theline\n",
    "\t\t\t\tbreak\n",
    "\tres = json.loads(res)\n",
    "\treturn extract_func(res)\n",
    "\n",
    "def extract_input(new_line):\n",
    "\treturn (new_line[\"messages\"])\n",
    "\n",
    "def upload_file(file_name: str, purpose: str) -> str:\n",
    "    with open(file_name, \"rb\") as file_fd:\n",
    "        response = client.files.create(file=file_fd, purpose=purpose)\n",
    "    return response.id"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
=======
   "execution_count": 30,
>>>>>>> d3ffed53bd2a6d389f460ba596891158a6ada8da
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROMPTS\n",
    "\n",
    "#AGE PROMPT\n",
    "categorize_system_prompt_paraphrase ='''\n",
    "La edad de adquisición (AoA) de una palabra se refiere a la edad en la que se aprendió una palabra por primera vez. \n",
    "En concreto, cuándo una persona habría entendido por primera vez esa palabra si alguien la hubiera utilizado delante de ella, incluso cuando aún no la hubiera dicho, leído o escrito. \n",
    "Calcule la edad media de adquisición (AoA) de la palabra {palabra} para un hablante nativo de español.\n",
    "\n",
    "El formato de salida debe ser un objeto JSON: {AoA: número //AoA de la palabra expresado en años, puede incluir decimales, Word: palabra //string}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
=======
   "execution_count": null,
>>>>>>> d3ffed53bd2a6d389f460ba596891158a6ada8da
   "metadata": {},
   "outputs": [],
   "source": [
    "#SET output folder\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "def out_file(file_name): return (str(output_folder) + file_name)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
=======
   "execution_count": null,
>>>>>>> d3ffed53bd2a6d389f460ba596891158a6ada8da
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE tasks from the database\n",
    "f_t_array = [create_f_t_array_from_dataframe(df,categorize_system_prompt_paraphrase)]\n",
    "f_t_file_array = [out_file(\"batch_job_mmlu_f_t_aoa_alonso.jsonl\"),out_file(\"batch_job_mmlu_check_aoa_alonso.jsonl\")]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEPARATE words in piles to fine-tune or check\n",
    "num_task_train = 2000\n",
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#SEPARATE words in piles to fine-tune or check\n",
    "num_task_train = 300\n",
>>>>>>> d3ffed53bd2a6d389f460ba596891158a6ada8da
    "\n",
    "#check all tasks in task array\n",
    "max_num_task = 0\n",
    "for i in range(0,len(f_t_array)):\n",
    "\tmax_num_task += len(f_t_array[i])\n",
    "\n",
    "#generate random task indexes\n",
    "random_num_array = []\n",
    "for i in range(0,num_task_train):\n",
    "\tnew_num = random.randrange(0,max_num_task)\n",
    "\twhile(new_num in random_num_array):\n",
    "\t\tnew_num = random.randrange(0,max_num_task)\n",
    "\trandom_num_array.append(new_num)\n",
    "\n",
    "#create training array and check array\n",
    "indiv = [[] for Null in range(len(f_t_file_array))]\n",
    "\n",
    "index_com = 0\n",
    "for i in range(0,len(f_t_array)):\n",
    "\ttasks = f_t_array[i]\n",
    "\tfor j in range(0,len(tasks)):\n",
    "\t\tif ((index_com+j)in random_num_array):\n",
    "\t\t\tindiv[0].append(tasks[j])\n",
    "\t\telse:\n",
    "\t\t\tindiv[1].append(tasks[j])\n",
    "\tindex_com += len(f_t_array[i])\n",
    "\n",
    "#create files\n",
    "for i in range(0,len(indiv)):\n",
    "\tcreate_file_from_tasks(indiv[i],f_t_file_array[i])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": null,
>>>>>>> d3ffed53bd2a6d389f460ba596891158a6ada8da
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN fine tuning file\n",
    "training_file_id = upload_file(f_t_file_array[0], \"fine-tune\")\n",
    "\n",
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file = training_file_id,\n",
    "    model = \"gpt-4o-mini-2024-07-18\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
=======
   "execution_count": null,
>>>>>>> d3ffed53bd2a6d389f460ba596891158a6ada8da
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succeeded\n",
<<<<<<< HEAD
      "ftjob-rHxNZYkt5qaQ3fnxKCRnwIOO\n"
=======
      "ftjob-b8EgveppLTEvsFEHBAZjBnth\n"
>>>>>>> d3ffed53bd2a6d389f460ba596891158a6ada8da
     ]
    }
   ],
   "source": [
    "#CHECK fine tuning progress\n",
    "f_t_job = client.fine_tuning.jobs.retrieve(job.id)\n",
    "print(f_t_job.status)\n",
    "print(f_t_job.id)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 37,
=======
   "execution_count": null,
>>>>>>> d3ffed53bd2a6d389f460ba596891158a6ada8da
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "FineTuningJob(id='ftjob-rHxNZYkt5qaQ3fnxKCRnwIOO', created_at=1741546791, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:ging-upm::B9GdDHzb', finished_at=1741548581, hyperparameters=Hyperparameters(batch_size=4, learning_rate_multiplier=1.8, n_epochs=3), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-b9e6eTH4lj1kn4VhwdRfE1Rx', result_files=['file-AvyYGXhsNMKT7BqHxrmEGN'], seed=1394683821, status='succeeded', trained_tokens=890304, training_file='file-7zDcAssm92DSgtkuSgLLa5', validation_file=None, estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size=4, learning_rate_multiplier=1.8, n_epochs=3)), type='supervised'), user_provided_suffix=None, metadata=None)\n",
      "ft:gpt-4o-mini-2024-07-18:ging-upm::B9GdDHzb\n"
=======
      "FineTuningJob(id='ftjob-b8EgveppLTEvsFEHBAZjBnth', created_at=1741374194, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:ging-upm::B8XeUNQT', finished_at=1741375680, hyperparameters=Hyperparameters(batch_size=1, learning_rate_multiplier=1.8, n_epochs=3), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-b9e6eTH4lj1kn4VhwdRfE1Rx', result_files=['file-267jqpk5CPy8GPodGa7FS5'], seed=2069854685, status='succeeded', trained_tokens=133464, training_file='file-C7rTwabzdBV1atMVHuUWqL', validation_file=None, estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size=1, learning_rate_multiplier=1.8, n_epochs=3)), type='supervised'), user_provided_suffix=None, metadata=None)\n"
>>>>>>> d3ffed53bd2a6d389f460ba596891158a6ada8da
     ]
    }
   ],
   "source": [
    "#EXTRACT fine tuned model\n",
    "fine_tuned_model_id = f_t_job.fine_tuned_model\n",
<<<<<<< HEAD
    "print(f_t_job)\n",
    "print(fine_tuned_model_id)"
=======
    "print(f_t_job)"
>>>>>>> d3ffed53bd2a6d389f460ba596891158a6ada8da
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 34,
=======
   "execution_count": null,
>>>>>>> d3ffed53bd2a6d389f460ba596891158a6ada8da
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST the rest of the words in database\n",
    "test_file = f_t_file_array[1]\n",
    "rows = []\n",
    "\n",
    "with open(test_file, 'r') as f:\n",
    "\t\tlines = len(f.readlines())\n",
    "\n",
    "for i in range(0,lines):\n",
    "\ttest_line = get_line_file(test_file,i,extract_input)\n",
    "\n",
    "\ttest_messages = []\n",
    "\ttest_messages.append(test_line[0])\n",
    "\ttest_messages.append(test_line[1])\n",
    "\tresponse = client.chat.completions.create(\n",
    "    \tmodel=fine_tuned_model_id, messages=test_messages, temperature=0\n",
    "\t)\n",
    "\trows.append({\n",
    "\t\t\"palabra\":test_line[1][\"content\"],\n",
    "\t\t\"AoA_ini\":test_line[2][\"content\"],\n",
    "\t\t\"AoA_IA\":response.choices[0].message.content\n",
    "\t})"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson_Corr: 0.9255576001337236\n",
      "Spearman_Corr: 0.9256739084721055\n"
     ]
    }
   ],
   "source": [
    "#SAVE ouput in a .xlsx file\n",
    "file_name = out_file(\"Prov_f_t_Results_\"+str(num_task_train)+\".xlsx\")\n",
    "clean_dtset = pd.DataFrame(rows)\n",
    "\n",
    "#CALCULATE correlation coeff\n",
    "cmp_clm_1 = \"AoA_ini\"\n",
    "cmp_clm_2 = \"AoA_IA\"\n",
    "\n",
    "pearson_corr = clean_dtset[[cmp_clm_1, cmp_clm_2]].corr('pearson')\n",
    "pearson_corr = pearson_corr[cmp_clm_1][cmp_clm_2]\n",
    "print(f\"Pearson_Corr: {pearson_corr}\")\n",
    "\t\n",
    "spearman_corr = clean_dtset[[cmp_clm_1, cmp_clm_2]].corr('spearman')\n",
    "spearman_corr = spearman_corr[cmp_clm_1][cmp_clm_2]\n",
    "print(f\"Spearman_Corr: {spearman_corr}\")\n",
    "\n",
    "stats = pd.DataFrame([{\n",
    "\t\"Pearson_Corr\":pearson_corr,\n",
    "\t\"Spearman_Corr\":spearman_corr\n",
    "}])\n",
    "\n",
    "#WRITE file\n",
    "with pd.ExcelWriter(file_name) as writer:\n",
    "\tclean_dtset.to_excel(writer, sheet_name='Results',index=False)\n",
    "\tstats.to_excel(writer, sheet_name='Stats',index=False)"
=======
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE ouput in a .xlsx file\n",
    "file_name = out_file(\"Prov_f_t_Results.xlsx\")\n",
    "clean_dtset = pd.DataFrame(rows)\n",
    "\n",
    "with pd.ExcelWriter(file_name) as writer:\n",
    "\tclean_dtset.to_excel(writer, sheet_name='Results',index=False)"
>>>>>>> d3ffed53bd2a6d389f460ba596891158a6ada8da
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": null,
>>>>>>> d3ffed53bd2a6d389f460ba596891158a6ada8da
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson_Corr: 0.8553013634512643\n",
      "Spearman_Corr: 0.8585083410985047\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "dataset_path = out_file(\"Prov_f_t_Results_300.xlsx\")\n",
    "df = pd.read_excel(dataset_path)\n",
    "\n",
    "cmp_clm_1 = \"AoA_ini\"\n",
    "cmp_clm_2 = \"AoA_IA\"\n",
    "\n",
    "pearson_corr = df[[cmp_clm_1, cmp_clm_2]].corr('pearson')\n",
    "pearson_corr = pearson_corr[cmp_clm_1][cmp_clm_2]\n",
    "print(f\"Pearson_Corr: {pearson_corr}\")\n",
    "\t\n",
    "spearman_corr = df[[cmp_clm_1, cmp_clm_2]].corr('spearman')\n",
    "spearman_corr = spearman_corr[cmp_clm_1][cmp_clm_2]\n",
    "print(f\"Spearman_Corr: {spearman_corr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.14\n"
     ]
    }
   ],
   "source": [
    "word = \"desconfinar\"\n",
    "test_messages_oneWord = [{\"role\": \"system\", \"content\": \"\\nLa edad de adquisici\\u00f3n (AoA) de una palabra se refiere a la edad en la que se aprendi\\u00f3 una palabra por primera vez. \\nEn concreto, cu\\u00e1ndo una persona habr\\u00eda entendido por primera vez esa palabra si alguien la hubiera utilizado delante de ella, incluso cuando a\\u00fan no la hubiera dicho, le\\u00eddo o escrito. \\nCalcule la edad media de adquisici\\u00f3n (AoA) de la palabra {palabra} para un hablante nativo de espa\\u00f1ol.\\n\\nEl formato de salida debe ser un objeto JSON: {AoA: n\\u00famero //AoA de la palabra expresado en a\\u00f1os, puede incluir decimales, Word: palabra //string}\\n\"}, {\"role\": \"user\", \"content\": word}]\n",
    "response = client.chat.completions.create(\n",
    "    \tmodel=fine_tuned_model_id, messages=test_messages, temperature=0\n",
    "\t)\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "line = {\"messages\": [\n",
    "\t{\"role\": \"system\", \"content\": \"\\nLa edad de adquisici\\u00f3n (AoA) de una palabra se refiere a la edad en la que se aprendi\\u00f3 una palabra por primera vez. \\nEn concreto, cu\\u00e1ndo una persona habr\\u00eda entendido por primera vez esa palabra si alguien la hubiera utilizado delante de ella, incluso cuando a\\u00fan no la hubiera dicho, le\\u00eddo o escrito. \\nCalcule la edad media de adquisici\\u00f3n (AoA) de la palabra {palabra} para un hablante nativo de espa\\u00f1ol.\\n\\nEl formato de salida debe ser un objeto JSON: {AoA: n\\u00famero //AoA de la palabra expresado en a\\u00f1os, puede incluir decimales, Word: palabra //string}\\n\"},\n",
    "\t{\"role\": \"user\", \"content\": word}, \n",
    "\t{\"role\": \"assistant\", \"content\": response.choices[0].message.content}\n",
    "\t]}\n",
    "\n",
    "with open(out_file(\"indiv_words_analisis.txt\"), 'a') as file1:\n",
    "    file1.write(str(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = os.getenv(\"DATASET_FOLDER\")\n",
    "dataset_path = str(dataset_folder) + \"GPT_estimates_AoA_v1.xlsx\"\n",
    "\n",
    "new_df = pd.read_excel(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = client.fine_tuning.jobs.list(limit=10)"
=======
    "#CALCULATE correlation coeff\n",
    "cmp_clm_1 = \"AoA_ini\"\n",
    "cmp_clm_2 = \"AoA_IA\"\n",
    "\n",
    "pearson_corr = clean_dtset[[cmp_clm_1, cmp_clm_2]].corr('pearson')\n",
    "print(f\"Pearson_Corr: {pearson_corr[cmp_clm_1][cmp_clm_2]}\")\n",
    "\t\n",
    "spearman_corr = clean_dtset[[cmp_clm_1, cmp_clm_2]].corr('spearman')\n",
    "print(f\"Spearman_Corr: {spearman_corr[cmp_clm_1][cmp_clm_2]}\")"
>>>>>>> d3ffed53bd2a6d389f460ba596891158a6ada8da
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

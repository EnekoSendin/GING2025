{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from openai import OpenAI #estamos la clase concreta OpenAI del módulo openai\n",
    "from dotenv import load_dotenv #importamos una función concreta del módulo\n",
    "load_dotenv(\"template.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a la clave de API de OpenAI\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Asegurarte de que la clave de API se haya cargado correctamente\n",
    "if api_key is None:\n",
    "\traise ValueError(\"La clave de API no está configurada en el archivo .env\")\n",
    "\n",
    "client = OpenAI() #creando un objeto de la clase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eneko\\Documents\\UniUPM\\BECA\\Lenguaje_interpret\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>averageAoA</th>\n",
       "      <th>SD</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>ItemZScore</th>\n",
       "      <th>OralFreq_Log</th>\n",
       "      <th>WrittenFreq_Subtlex-ESP_Log</th>\n",
       "      <th>WrittenFreq_LEXESP_Log</th>\n",
       "      <th>WrittenFreq_espal_Log</th>\n",
       "      <th>espal_max_lem_cat</th>\n",
       "      <th>max_lem_code</th>\n",
       "      <th>espal_es_num_syll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.443352</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.650147</td>\n",
       "      <td>4.851582</td>\n",
       "      <td>5.984858</td>\n",
       "      <td>4.960556</td>\n",
       "      <td>4.358684</td>\n",
       "      <td>ADPOSITION</td>\n",
       "      <td>SPS00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abajo</td>\n",
       "      <td>2.96</td>\n",
       "      <td>1.369642</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.356683</td>\n",
       "      <td>2.615950</td>\n",
       "      <td>3.940915</td>\n",
       "      <td>2.750508</td>\n",
       "      <td>1.811229</td>\n",
       "      <td>ADVERB</td>\n",
       "      <td>RG</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandonado</td>\n",
       "      <td>6.06</td>\n",
       "      <td>1.658743</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.584383</td>\n",
       "      <td>1.623249</td>\n",
       "      <td>2.872156</td>\n",
       "      <td>2.195900</td>\n",
       "      <td>1.374186</td>\n",
       "      <td>ADJECTIVE</td>\n",
       "      <td>AQ0MSP</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandonar</td>\n",
       "      <td>7.58</td>\n",
       "      <td>1.654801</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.019940</td>\n",
       "      <td>1.806180</td>\n",
       "      <td>2.987666</td>\n",
       "      <td>2.434569</td>\n",
       "      <td>1.653307</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VMN0000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandono</td>\n",
       "      <td>7.22</td>\n",
       "      <td>1.940860</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0.040498</td>\n",
       "      <td>1.602060</td>\n",
       "      <td>2.336460</td>\n",
       "      <td>2.167317</td>\n",
       "      <td>1.328129</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NCMS000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  averageAoA        SD  Min  Max  ItemZScore  OralFreq_Log  \\\n",
       "0           a        2.28  1.443352    1    6   -1.650147      4.851582   \n",
       "1       abajo        2.96  1.369642    1    6   -1.356683      2.615950   \n",
       "2  abandonado        6.06  1.658743    2   10   -0.584383      1.623249   \n",
       "3   abandonar        7.58  1.654801    4   11   -0.019940      1.806180   \n",
       "4    abandono        7.22  1.940860    3   11    0.040498      1.602060   \n",
       "\n",
       "    WrittenFreq_Subtlex-ESP_Log   WrittenFreq_LEXESP_Log  \\\n",
       "0                      5.984858                 4.960556   \n",
       "1                      3.940915                 2.750508   \n",
       "2                      2.872156                 2.195900   \n",
       "3                      2.987666                 2.434569   \n",
       "4                      2.336460                 2.167317   \n",
       "\n",
       "   WrittenFreq_espal_Log espal_max_lem_cat max_lem_code  espal_es_num_syll  \n",
       "0               4.358684        ADPOSITION        SPS00                1.0  \n",
       "1               1.811229            ADVERB           RG                3.0  \n",
       "2               1.374186         ADJECTIVE       AQ0MSP                5.0  \n",
       "3               1.653307              VERB      VMN0000                4.0  \n",
       "4               1.328129              NOUN      NCMS000                4.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_folder = os.getenv(\"DATASET_FOLDER\")\n",
    "dataset_path = str(dataset_folder) + \"Alonso_2014_SpanishAoA.xlsx\"\n",
    "\n",
    "df = pd.read_excel(dataset_path)\n",
    "#df = df.sample(5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION DECLARATION\n",
    "\n",
    "def generate_task(index,prompt,desc):\n",
    "\ttask = {\n",
    "\t\t\"custom_id\": f\"task-{index}\",\n",
    "\t\t\"method\": \"POST\",\n",
    "\t\t\"url\": \"/v1/chat/completions\",\n",
    "\t\t\"body\": {\n",
    "\t\t\t# Esto es lo que tendrías en tu llamada a la API de Chat Completions\n",
    "\t\t\t\"model\": \"gpt-4o-mini\",\n",
    "\t\t\t\"temperature\": 0,\n",
    "\t\t\t\"response_format\": { \n",
    "\t\t\t\t\"type\": \"json_object\"\n",
    "\t\t\t},\n",
    "\t\t\t\"messages\": [\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\"role\": \"system\",\n",
    "\t\t\t\t\"content\": prompt\n",
    "\t\t\t\t},\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\"role\": \"user\",\n",
    "\t\t\t\t\"content\": desc\n",
    "\t\t\t\t}\n",
    "\t\t\t],\n",
    "\t\t}\n",
    "\t}\n",
    "\treturn task\n",
    "\n",
    "def generate_fine_tuning(prompt,word,aoa):\n",
    "\tf_t_line = {\n",
    "\t\t\"messages\": [\n",
    "\t\t\t{ \"role\": \"system\", \"content\": str(prompt) },\n",
    "\t\t\t{ \"role\": \"user\", \"content\": str(word) },\n",
    "\t\t\t{ \"role\": \"assistant\", \"content\": str(aoa) }\n",
    "\t\t]}\n",
    "\treturn f_t_line\n",
    "\n",
    "def create_file_from_tasks(tasks,file_name):\n",
    "\twith open(file_name, 'w') as file:\n",
    "\t\tfor obj in tasks:\n",
    "\t\t\tfile.write(json.dumps(obj) + '\\n')\n",
    "\n",
    "\n",
    "def create_fine_tunning_from_json(json_object,prompt):\n",
    "\tword = json_object[\"word\"]\n",
    "\taoa = json_object[\"averageAoA\"]\n",
    "\tf_t_line = generate_fine_tuning(\n",
    "\t\tprompt,word,aoa\n",
    "\t\t)\n",
    "\treturn f_t_line\n",
    "\n",
    "\n",
    "def create_f_t_array_from_dataframe(df,prompt):\n",
    "\ttasks = []\n",
    "\tfor index, row in df.iterrows():\n",
    "\t\ttask = create_fine_tunning_from_json(row,prompt)\n",
    "\t\ttasks.append(task)\n",
    "\treturn tasks\n",
    "\n",
    "\n",
    "def get_line_file(file_name,line,extract_func):\n",
    "\twith open(file_name, 'r') as f:\n",
    "\t\tfor line_number, theline in enumerate(f):\n",
    "\t\t\tif line_number == line:\n",
    "\t\t\t\tres = theline\n",
    "\t\t\t\tbreak\n",
    "\tres = json.loads(res)\n",
    "\treturn extract_func(res)\n",
    "\n",
    "\n",
    "def extract_input(new_line):\n",
    "\treturn (new_line[\"messages\"])\n",
    "\n",
    "\n",
    "def upload_file(file_name: str, purpose: str) -> str:\n",
    "    with open(file_name, \"rb\") as file_fd:\n",
    "        response = client.files.create(file=file_fd, purpose=purpose)\n",
    "    return response.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROMPTS\n",
    "\n",
    "#AGE PROMPT\n",
    "categorize_system_prompt_paraphrase ='''\n",
    "La edad de adquisición (AoA) de una palabra se refiere a la edad en la que se aprendió una palabra por primera vez. \n",
    "En concreto, cuándo una persona habría entendido por primera vez esa palabra si alguien la hubiera utilizado delante de ella, incluso cuando aún no la hubiera dicho, leído o escrito. \n",
    "Calcule la edad media de adquisición (AoA) de la palabra {palabra} para un hablante nativo de español.\n",
    "\n",
    "El formato de salida debe ser un objeto JSON: {AoA: número //AoA de la palabra expresado en años, puede incluir decimales, Word: palabra //string}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SET output folder\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "def out_file(file_name): return (str(output_folder) + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE tasks from the database\n",
    "f_t_array = [create_f_t_array_from_dataframe(df,categorize_system_prompt_paraphrase)]\n",
    "f_t_file_array = [out_file(\"batch_job_mmlu_f_t_aoa_alonso.jsonl\"),out_file(\"batch_job_mmlu_check_aoa_alonso.jsonl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEPARATE words in piles to fine-tune or check\n",
    "num_task_train = 2000\n",
    "\n",
    "#check all tasks in task array\n",
    "max_num_task = 0\n",
    "for i in range(0,len(f_t_array)):\n",
    "\tmax_num_task += len(f_t_array[i])\n",
    "\n",
    "#generate random task indexes\n",
    "random_num_array = []\n",
    "for i in range(0,num_task_train):\n",
    "\tnew_num = random.randrange(0,max_num_task)\n",
    "\twhile(new_num in random_num_array):\n",
    "\t\tnew_num = random.randrange(0,max_num_task)\n",
    "\trandom_num_array.append(new_num)\n",
    "\n",
    "#create training array and check array\n",
    "indiv = [[] for Null in range(len(f_t_file_array))]\n",
    "\n",
    "index_com = 0\n",
    "for i in range(0,len(f_t_array)):\n",
    "\ttasks = f_t_array[i]\n",
    "\tfor j in range(0,len(tasks)):\n",
    "\t\tif ((index_com+j)in random_num_array):\n",
    "\t\t\tindiv[0].append(tasks[j])\n",
    "\t\telse:\n",
    "\t\t\tindiv[1].append(tasks[j])\n",
    "\tindex_com += len(f_t_array[i])\n",
    "\n",
    "#create files\n",
    "for i in range(0,len(indiv)):\n",
    "\tcreate_file_from_tasks(indiv[i],f_t_file_array[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Invalid file format for Fine-Tuning API. Must be .jsonl', 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#TRAIN fine tuning file\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m training_file_id = \u001b[43mupload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_t_file_array\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfine-tune\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m job = client.fine_tuning.jobs.create(\n\u001b[32m      5\u001b[39m \t\ttraining_file = training_file_id,\n\u001b[32m      6\u001b[39m \t\tmodel = \u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini-2024-07-18\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m \t)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mupload_file\u001b[39m\u001b[34m(file_name, purpose)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupload_file\u001b[39m(file_name: \u001b[38;5;28mstr\u001b[39m, purpose: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_name, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file_fd:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m         response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile_fd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpurpose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpurpose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Eneko\\Documents\\UniUPM\\BECA\\Lenguaje_interpret\\.venv\\Lib\\site-packages\\openai\\resources\\files.py:127\u001b[39m, in \u001b[36mFiles.create\u001b[39m\u001b[34m(self, file, purpose, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# It should be noted that the actual Content-Type header that will be\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# sent to the server will contain a `boundary` parameter, e.g.\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# multipart/form-data; boundary=---abc--\u001b[39;00m\n\u001b[32m    126\u001b[39m extra_headers = {\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmultipart/form-data\u001b[39m\u001b[33m\"\u001b[39m, **(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/files\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFileCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFileObject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Eneko\\Documents\\UniUPM\\BECA\\Lenguaje_interpret\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1296\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1282\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1283\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1284\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1291\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1292\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1293\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1294\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1295\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1296\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Eneko\\Documents\\UniUPM\\BECA\\Lenguaje_interpret\\.venv\\Lib\\site-packages\\openai\\_base_client.py:973\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    970\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    971\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m973\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Eneko\\Documents\\UniUPM\\BECA\\Lenguaje_interpret\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1077\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1074\u001b[39m         err.response.read()\n\u001b[32m   1076\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1077\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1079\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1080\u001b[39m     cast_to=cast_to,\n\u001b[32m   1081\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1085\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1086\u001b[39m )\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': 'Invalid file format for Fine-Tuning API. Must be .jsonl', 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "#TRAIN fine tuning file\n",
    "training_file_id = upload_file(f_t_file_array[0], \"fine-tune\")\n",
    "\n",
    "job = client.fine_tuning.jobs.create(\n",
    "\t\ttraining_file = training_file_id,\n",
    "\t\tmodel = \"gpt-4o-mini-2024-07-18\",\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK fine tuning progress\n",
    "f_t_job = client.fine_tuning.jobs.retrieve(job.id)\n",
    "print(f_t_job.status)\n",
    "print(f_t_job.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXTRACT fine tuned model\n",
    "fine_tuned_model_id = f_t_job.fine_tuned_model\n",
    "print(f_t_job)\n",
    "print(fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST the rest of the words in database\n",
    "test_file = f_t_file_array[1]\n",
    "rows = []\n",
    "\n",
    "with open(test_file, 'r') as f:\n",
    "\tlines = len(f.readlines())\n",
    "\n",
    "for i in range(0,lines):\n",
    "\ttest_line = get_line_file(test_file,i,extract_input)\n",
    "\n",
    "\ttest_messages = []\n",
    "\ttest_messages.append(test_line[0])\n",
    "\ttest_messages.append(test_line[1])\n",
    "\tresponse = client.chat.completions.create(\n",
    "\t\tmodel=fine_tuned_model_id, messages=test_messages, temperature=0\n",
    "\t)\n",
    "\trows.append({\n",
    "\t\t\"palabra\":test_line[1][\"content\"],\n",
    "\t\t\"AoA_ini\":test_line[2][\"content\"],\n",
    "\t\t\"AoA_IA\":response.choices[0].message.content\n",
    "\t})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE ouput in a .xlsx file\n",
    "file_name = out_file(\"Prov_f_t_Results_\"+str(num_task_train)+\".xlsx\")\n",
    "clean_dtset = pd.DataFrame(rows)\n",
    "\n",
    "#CALCULATE correlation coeff\n",
    "cmp_clm_1 = \"AoA_ini\"\n",
    "cmp_clm_2 = \"AoA_IA\"\n",
    "\n",
    "pearson_corr = clean_dtset[[cmp_clm_1, cmp_clm_2]].corr('pearson')\n",
    "pearson_corr = pearson_corr[cmp_clm_1][cmp_clm_2]\n",
    "print(f\"Pearson_Corr: {pearson_corr}\")\n",
    "\n",
    "spearman_corr = clean_dtset[[cmp_clm_1, cmp_clm_2]].corr('spearman')\n",
    "spearman_corr = spearman_corr[cmp_clm_1][cmp_clm_2]\n",
    "print(f\"Spearman_Corr: {spearman_corr}\")\n",
    "\n",
    "stats = pd.DataFrame([{\n",
    "\t\"Pearson_Corr\":pearson_corr,\n",
    "\t\"Spearman_Corr\":spearman_corr\n",
    "\t}])\n",
    "\n",
    "#WRITE file\n",
    "with pd.ExcelWriter(file_name) as writer:\n",
    "\tclean_dtset.to_excel(writer, sheet_name='Results',index=False)\n",
    "\tstats.to_excel(writer, sheet_name='Stats',index=False)\n",
    "\n",
    "#SAVE ouput in a .xlsx file\n",
    "file_name = out_file(\"Prov_f_t_Results.xlsx\")\n",
    "clean_dtset = pd.DataFrame(rows)\n",
    "\n",
    "with pd.ExcelWriter(file_name) as writer:\n",
    "\tclean_dtset.to_excel(writer, sheet_name='Results',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = out_file(\"Prov_f_t_Results_300.xlsx\")\n",
    "df = pd.read_excel(dataset_path)\n",
    "\n",
    "cmp_clm_1 = \"AoA_ini\"\n",
    "cmp_clm_2 = \"AoA_IA\"\n",
    "\n",
    "pearson_corr = df[[cmp_clm_1, cmp_clm_2]].corr('pearson')\n",
    "pearson_corr = pearson_corr[cmp_clm_1][cmp_clm_2]\n",
    "print(f\"Pearson_Corr: {pearson_corr}\")\n",
    "\n",
    "spearman_corr = df[[cmp_clm_1, cmp_clm_2]].corr('spearman')\n",
    "spearman_corr = spearman_corr[cmp_clm_1][cmp_clm_2]\n",
    "print(f\"Spearman_Corr: {spearman_corr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"desconfinar\"\n",
    "test_messages_oneWord = [{\"role\": \"system\", \"content\": \"\\nLa edad de adquisici\\\\u00f3n (AoA) de una palabra se refiere a la edad en la que se aprendi\\\\u00f3 una palabra por primera vez. \\\\nEn concreto, cu\\\\u00e1ndo una persona habr\\\\u00eda entendido por primera vez esa palabra si alguien la hubiera utilizado delante de ella, incluso cuando a\\\\u00fan no la hubiera dicho, le\\\\u00eddo o escrito. \\\\nCalcule la edad media de adquisici\\\\u00f3n (AoA) de la palabra {palabra} para un hablante nativo de espa\\\\u00f1ol.\\\\n\\\\nEl formato de salida debe ser un objeto JSON: {AoA: n\\\\u00famero //AoA de la palabra expresado en a\\\\u00f1os, puede incluir decimales, Word: palabra //string}\\n\"}, {\"role\": \"user\", \"content\": word}]\n",
    "response = client.chat.completions.create(\n",
    "\tmodel=fine_tuned_model_id, messages=test_messages, temperature=0\n",
    "\t)\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "line = {\"messages\": [\n",
    "\t{\"role\": \"system\", \"content\": \"\\nLa edad de adquisici\\\\u00f3n (AoA) de una palabra se refiere a la edad en la que se aprendi\\\\u00f3 una palabra por primera vez. \\\\nEn concreto, cu\\\\u00e1ndo una persona habr\\\\u00eda entendido por primera vez esa palabra si alguien la hubiera utilizado delante de ella, incluso cuando a\\\\u00fan no la hubiera dicho, le\\\\u00eddo o escrito. \\\\nCalcule la edad media de adquisici\\\\u00f3n (AoA) de la palabra {palabra} para un hablante nativo de espa\\\\u00f1ol.\\\\n\\\\nEl formato de salida debe ser un objeto JSON: {AoA: n\\\\u00famero //AoA de la palabra expresado en a\\\\u00f1os, puede incluir decimales, Word: palabra //string}\\n\"},\n",
    "\t{\"role\": \"user\", \"content\": word}, \n",
    "\t{\"role\": \"assistant\", \"content\": response.choices[0].message.content}\n",
    "\t]}\n",
    "\n",
    "with open(out_file(\"indiv_words_analisis.txt\"), 'a') as file1:\n",
    "\tfile1.write(str(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULATE correlation coeff\n",
    "cmp_clm_1 = \"AoA_ini\"\n",
    "cmp_clm_2 = \"AoA_IA\"\n",
    "\n",
    "pearson_corr = clean_dtset[[cmp_clm_1, cmp_clm_2]].corr('pearson')\n",
    "print(f\"Pearson_Corr: {pearson_corr[cmp_clm_1][cmp_clm_2]}\")\n",
    "\n",
    "spearman_corr = clean_dtset[[cmp_clm_1, cmp_clm_2]].corr('spearman')\n",
    "print(f\"Spearman_Corr: {spearman_corr[cmp_clm_1][cmp_clm_2]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
